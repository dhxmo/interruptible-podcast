{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660912bd-4543-4e32-bf46-04769c6c7837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TTS\n",
      "  Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: cython>=0.29.30 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (3.0.11)\n",
      "Requirement already satisfied: scipy>=1.11.2 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (1.15.2)\n",
      "Requirement already satisfied: torch>=2.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (2.5.1)\n",
      "Requirement already satisfied: torchaudio in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (2.5.1)\n",
      "Requirement already satisfied: soundfile>=0.12.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (0.13.1)\n",
      "Requirement already satisfied: librosa>=0.10.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (0.10.2.post1)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (1.6.1)\n",
      "Collecting inflect>=5.6.0 (from TTS)\n",
      "  Using cached inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (4.66.5)\n",
      "Collecting anyascii>=0.3.0 (from TTS)\n",
      "  Using cached anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.6.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (3.11.13)\n",
      "Requirement already satisfied: packaging>=23.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (24.1)\n",
      "Collecting flask>=2.0.1 (from TTS)\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pysbd>=0.3.4 (from TTS)\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting umap-learn>=0.5.1 (from TTS)\n",
      "  Using cached umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pandas<2.0,>=1.4 (from TTS)\n",
      "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (3.10.0)\n",
      "Collecting trainer>=0.0.32 (from TTS)\n",
      "  Using cached trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting coqpit>=0.0.16 (from TTS)\n",
      "  Using cached coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jieba (from TTS)\n",
      "  Using cached jieba-0.42.1.tar.gz (19.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pypinyin (from TTS)\n",
      "  Using cached pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting hangul-romanize (from TTS)\n",
      "  Using cached hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut-2.2.3.tar.gz (73 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jamo (from TTS)\n",
      "  Using cached jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: nltk in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (3.9.1)\n",
      "Collecting g2pkk>=0.1.1 (from TTS)\n",
      "  Using cached g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting bangla (from TTS)\n",
      "  Using cached bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting bnnumerizer (from TTS)\n",
      "  Using cached bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bnunicodenormalizer (from TTS)\n",
      "  Using cached bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: einops>=0.6.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (0.8.1)\n",
      "Requirement already satisfied: transformers>=4.33.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (4.49.0)\n",
      "Collecting encodec>=0.1.1 (from TTS)\n",
      "  Using cached encodec-0.1.1.tar.gz (3.7 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting unidecode>=1.3.2 (from TTS)\n",
      "  Using cached Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting num2words (from TTS)\n",
      "  Using cached num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting spacy>=3 (from spacy[ja]>=3->TTS)\n",
      "  Downloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: numpy>=1.24.3 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (1.26.4)\n",
      "Requirement already satisfied: numba>=0.57.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from TTS) (0.60.0)\n",
      "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.16.0)\n",
      "Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
      "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut-ipa-0.13.0.tar.gz (101 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from aiohttp>=3.8.1->TTS) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from aiohttp>=3.8.1->TTS) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from aiohttp>=3.8.1->TTS) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from aiohttp>=3.8.1->TTS) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from aiohttp>=3.8.1->TTS) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from aiohttp>=3.8.1->TTS) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from aiohttp>=3.8.1->TTS) (1.18.3)\n",
      "Collecting Werkzeug>=3.1 (from flask>=2.0.1->TTS)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from flask>=2.0.1->TTS) (3.1.4)\n",
      "Collecting itsdangerous>=2.2 (from flask>=2.0.1->TTS)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from flask>=2.0.1->TTS) (8.1.8)\n",
      "Collecting blinker>=1.9 (from flask>=2.0.1->TTS)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: more_itertools>=8.5.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from inflect>=5.6.0->TTS) (10.6.0)\n",
      "Collecting typeguard>=4.0.1 (from inflect>=5.6.0->TTS)\n",
      "  Using cached typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from librosa>=0.10.0->TTS) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from librosa>=0.10.0->TTS) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from librosa>=0.10.0->TTS) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from librosa>=0.10.0->TTS) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from librosa>=0.10.0->TTS) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from librosa>=0.10.0->TTS) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from librosa>=0.10.0->TTS) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from matplotlib>=3.7.0->TTS) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from matplotlib>=3.7.0->TTS) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from matplotlib>=3.7.0->TTS) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from matplotlib>=3.7.0->TTS) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from matplotlib>=3.7.0->TTS) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from matplotlib>=3.7.0->TTS) (2.9.0.post0)\n",
      "Collecting docopt>=0.6.2 (from num2words->TTS)\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from numba>=0.57.0->TTS) (0.43.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from pandas<2.0,>=1.4->TTS) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from scikit-learn>=1.3.0->TTS) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from soundfile>=0.12.0->TTS) (1.17.1)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Downloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.10.6)\n",
      "Requirement already satisfied: setuptools in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (75.1.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\n",
      "  Downloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting sudachidict_core>=20211220 (from spacy[ja]>=3->TTS)\n",
      "  Using cached SudachiDict_core-20250129-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: filelock in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (3.17.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from torch>=2.1->TTS) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.1->TTS) (1.3.0)\n",
      "Requirement already satisfied: psutil in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from trainer>=0.0.32->TTS) (7.0.0)\n",
      "Collecting tensorboard (from trainer>=0.0.32->TTS)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from transformers>=4.33.0->TTS) (0.29.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from transformers>=4.33.0->TTS) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from transformers>=4.33.0->TTS) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from transformers>=4.33.0->TTS) (0.5.3)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS)\n",
      "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pycparser in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.22)\n",
      "Collecting tzlocal (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n",
      "  Using cached tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS) (3.0.1)\n",
      "Requirement already satisfied: six in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (4.3.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2024.8.30)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Downloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->trainer>=0.0.32->TTS)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from tensorboard->trainer>=0.0.32->TTS) (1.66.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->trainer>=0.0.32->TTS)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from tensorboard->trainer>=0.0.32->TTS) (5.28.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->trainer>=0.0.32->TTS)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dhxmo/miniconda3/envs/test_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (0.1.2)\n",
      "Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl (937 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "Using cached coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
      "Using cached inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "Using cached num2words-0.5.14-py3-none-any.whl (163 kB)\n",
      "Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Downloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached trainer-0.0.36-py3-none-any.whl (51 kB)\n",
      "Using cached umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
      "Using cached Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "Using cached bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
      "Using cached bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
      "Using cached hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
      "Using cached jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
      "Using cached pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
      "Using cached dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
      "Using cached networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
      "Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hUsing cached SudachiDict_core-20250129-py3-none-any.whl (72.1 MB)\n",
      "Downloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Building wheels for collected packages: gruut, encodec, bnnumerizer, jieba, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n",
      "  Building wheel for gruut (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75788 sha256=65e4e33585c3e00f7c63bba9a4ae94124ba50ba1791588c71d4cec4f898a1964\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/1f/a0/bc/4dacab52579ab464cffafbe7a8e3792dd36ad9ac288b264843\n",
      "  Building wheel for encodec (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=894e71eb9f1f2885cc5491f62cb101a0fca86b170c4036db6de142d7fdf4e905\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/b4/a4/88/480018a664e58ca7ce6708759193ee51b017b3b72aa3df8a85\n",
      "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=bd935191aaf33c9e1d4f932acf3f299ecaac2be573127736c03187438038c6e7\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/9e/b9/e3/4145416693824818c0b931988a692676ecd4bbf2ea41d1eedd\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=ee422ed854334622109041a72c87a8afaf906e2bd99b2983f4c3434f68324e60\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/ac/60/cf/538a1f183409caf1fc136b5d2c2dee329001ef6da2c5084bef\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c5b06b55994a6cb59725e8124ee2921c0de9a28552f6322b95b8e6848fdf88b9\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=90a437dd228dbada6a139212364b608d29b2c2387086c0427a55b84a60d510e0\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/c7/10/89/a5908dd7a9a032229684b7679396785e19f816667f788087fb\n",
      "  Building wheel for gruut_lang_de (setup.py) ... \u001b[done\n",
      "\u001b[?25h  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498313 sha256=54e0abb3094e8e1125dad5ed2b6748d98bfa2c5cadebf123aa01439207b98486\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/87/fa/df/5fdf5d3cc26ba859b8698a1f28581d1a6aa081edc6df9847ab\n",
      "  Building wheel for gruut_lang_en (setup.py) ... \u001bdone\n",
      "\u001b[?25h  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326857 sha256=a19fde7e3ae675092e8a70bac6ff77b40508e679114f399b0e39508a6ee892c6\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/06/30/52/dc5cd222b4bbde285838fed1f96636e96f85cd75493e79a978\n",
      "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?done\n",
      "\u001b[?25h  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173928 sha256=d29a3e515301b42363c7961741beb820e71b2c0f233205a75f9fb1bc6ee7414a\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/c8/eb/59/30b5d15e56347e595f613036cbea0f807ad9621c75cd75d912\n",
      "  Building wheel for gruut_lang_fr (setup.py) ... \u001bdone\n",
      "\u001b[?25h  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=a3b25736efb26648c15f9d5b06b2ca44c1acf56bd2e7447bdb8996305ec0dbc3\n",
      "  Stored in directory: /home/dhxmo/.cache/pip/wheels/e0/e7/a0/7c416a3eeaa94ca71bf7bcbc6289cced2263d8ba35e82444bb\n",
      "Successfully built gruut encodec bnnumerizer jieba docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n",
      "Installing collected packages: sudachipy, jieba, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, cymem, bnunicodenormalizer, bnnumerizer, bangla, Werkzeug, wasabi, unidecode, tzlocal, typeguard, tensorboard-data-server, sudachidict_core, spacy-loggers, spacy-legacy, smart-open, python-crfsuite, pysbd, pypinyin, num2words, networkx, murmurhash, markdown, marisa-trie, jsonlines, itsdangerous, gruut-ipa, coqpit, cloudpathlib, catalogue, blis, blinker, anyascii, absl-py, tensorboard, srsly, preshed, pandas, language-data, inflect, g2pkk, flask, dateparser, pynndescent, langcodes, gruut, confection, weasel, umap-learn, trainer, thinc, spacy, encodec, TTS\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.4.2\n",
      "    Uninstalling networkx-3.4.2:\n",
      "      Successfully uninstalled networkx-3.4.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "Successfully installed TTS-0.22.0 Werkzeug-3.1.3 absl-py-2.1.0 anyascii-0.3.2 bangla-0.0.2 blinker-1.9.0 blis-1.2.0 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 coqpit-0.0.17 cymem-2.0.11 dateparser-1.1.8 docopt-0.6.2 encodec-0.1.1 flask-3.1.0 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 inflect-7.5.0 itsdangerous-2.2.0 jamo-0.4.1 jieba-0.42.1 jsonlines-1.2.0 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-3.7 murmurhash-1.0.12 networkx-2.8.8 num2words-0.5.14 pandas-1.5.3 preshed-3.0.9 pynndescent-0.5.13 pypinyin-0.53.0 pysbd-0.3.4 python-crfsuite-0.9.11 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 sudachidict_core-20250129 sudachipy-0.6.10 tensorboard-2.19.0 tensorboard-data-server-0.7.2 thinc-8.3.4 trainer-0.0.36 typeguard-4.4.2 tzlocal-5.3.1 umap-learn-0.5.7 unidecode-1.3.8 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install TTS  # from PyPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cb995-364c-4ce4-9eec-8091d013be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "# tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=False)\n",
    "\n",
    "# generate speech by cloning a voice using default settings\n",
    "tts.tts_to_file(\n",
    "    text=\"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\",\n",
    "    file_path=\"output.wav\",\n",
    "    speaker=\"Ana Florence\",\n",
    "    language=\"en\",\n",
    "    split_sentences=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69dc767b-5dda-4e9d-9195-df165b7de200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66871e9-d2d1-40d8-a62d-af03389d4853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89dfa326-8a1f-4181-ba3b-1f002883a5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81420b6b-11a9-4341-9b43-2eed35d448b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['Hey, have you heard about this new text-to-audio model called \"Bark\"?']\n",
      " > Processing time: 2.0986294746398926\n",
      " > Real-time factor: 0.3378312982990424\n",
      " > Text splitted to sentences.\n",
      "[\"Apparently, it's the most realistic and natural-sounding text-to-audio model  out there right now.\"]\n",
      " > Processing time: 2.3255832195281982\n",
      " > Real-time factor: 0.3288809004014673\n",
      " > Text splitted to sentences.\n",
      "['People are saying it sounds just like a real person speaking.']\n",
      " > Processing time: 1.4221363067626953\n",
      " > Real-time factor: 0.3392559456045247\n",
      " > Text splitted to sentences.\n",
      "['I think it uses advanced machine learning algorithms to analyze and understand the  nuances of human speech, and then replicates those nuances in its own speech output.']\n",
      " > Processing time: 4.450601816177368\n",
      " > Real-time factor: 0.3181103484217331\n",
      " > Text splitted to sentences.\n",
      "[\"It's pretty impressive, and I bet it could be used for things like audiobooks or podcasts.\"]\n",
      " > Processing time: 2.9789555072784424\n",
      " > Real-time factor: 0.31557944949405053\n",
      " > Text splitted to sentences.\n",
      "['In fact, I heard that some publishers are already starting to use Bark to create audiobooks.']\n",
      " > Processing time: 2.6254310607910156\n",
      " > Real-time factor: 0.3171331563373318\n",
      " > Text splitted to sentences.\n",
      "['It would be like having your own personal voiceover artist.']\n",
      " > Processing time: 1.9613001346588135\n",
      " > Real-time factor: 0.331849815601802\n",
      " > Text splitted to sentences.\n",
      "['I really think Bark is going to  be a game-changer in the world of text-to-audio technology.']\n",
      " > Processing time: 1.9179470539093018\n",
      " > Real-time factor: 0.33035505357689743\n",
      "Final audio saved as output.wav\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "# Initialize TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
    "\n",
    "scripts = \"\"\"Hey, have you heard about this new text-to-audio model called \"Bark\"? \n",
    "Apparently, it's the most realistic and natural-sounding text-to-audio model \n",
    "out there right now. People are saying it sounds just like a real person speaking. \n",
    "I think it uses advanced machine learning algorithms to analyze and understand the \n",
    "nuances of human speech, and then replicates those nuances in its own speech output. \n",
    "It's pretty impressive, and I bet it could be used for things like audiobooks or podcasts. \n",
    "In fact, I heard that some publishers are already starting to use Bark to create audiobooks. \n",
    "It would be like having your own personal voiceover artist. I really think Bark is going to \n",
    "be a game-changer in the world of text-to-audio technology.\"\"\".replace(\n",
    "    \"\\n\", \" \"\n",
    ").strip()\n",
    "\n",
    "sentences = nltk.sent_tokenize(scripts)\n",
    "\n",
    "# Path to the target speaker's voice\n",
    "speaker_wav = [\"Voice_1.wav\"]\n",
    "\n",
    "# Temporary folder for storing audio chunks\n",
    "temp_files = []\n",
    "\n",
    "# Generate audio files for each sentence\n",
    "for i, sentence in enumerate(sentences):\n",
    "    temp_path = f\"temp_{i}.wav\"\n",
    "    tts.tts_to_file(\n",
    "        text=sentence, file_path=temp_path, speaker_wav=speaker_wav, language=\"en\"\n",
    "    )\n",
    "    temp_files.append(temp_path)\n",
    "\n",
    "# Load and concatenate audio files\n",
    "final_audio = AudioSegment.empty()\n",
    "for file in temp_files:\n",
    "    audio = AudioSegment.from_wav(file)\n",
    "    # final_audio += audio + AudioSegment.silent(duration=500)  # Adding a small pause between sentences\n",
    "    final_audio += audio\n",
    "\n",
    "# Export the concatenated audio\n",
    "final_audio.export(\"output.wav\", format=\"wav\")\n",
    "\n",
    "# Cleanup temporary files\n",
    "for file in temp_files:\n",
    "    os.remove(file)\n",
    "\n",
    "print(\"Final audio saved as output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdca504a-f1db-484c-8a79-c40a2a675433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['Hey, have you heard about this new text-to-audio model called \"Bark\"?']\n",
      " > Processing time: 1.6642100811004639\n",
      " > Real-time factor: 0.3235279331381826\n",
      " > Text splitted to sentences.\n",
      "[\"No, I haven't.\", \"What's so special about it?\"]\n",
      " > Processing time: 1.7830893993377686\n",
      " > Real-time factor: 0.3646957670617932\n",
      " > Text splitted to sentences.\n",
      "[\"Well, apparently it's the most realistic and natural-sounding text-to-audio model out there right now.\", 'People are saying it sounds just like a real person speaking.']\n",
      " > Processing time: 3.835374116897583\n",
      " > Real-time factor: 0.3113220022882249\n",
      " > Text splitted to sentences.\n",
      "['Wow, that sounds amazing.', 'How does it work?']\n",
      " > Processing time: 1.8660781383514404\n",
      " > Real-time factor: 0.3397211273996802\n",
      " > Text splitted to sentences.\n",
      "['I think it uses advanced machine learning algorithms to analyze and understand the nuances of human speech, and then replicates those nuances in its own speech output.']\n",
      " > Processing time: 3.9521496295928955\n",
      " > Real-time factor: 0.28871222943454594\n",
      " > Text splitted to sentences.\n",
      "[\"That's pretty impressive.\", 'Do you think it could be used for things like audiobooks or podcasts?']\n",
      " > Processing time: 3.663370370864868\n",
      " > Real-time factor: 0.3010484372300624\n",
      " > Text splitted to sentences.\n",
      "['Definitely!', 'In fact, I heard that some publishers are already starting to use Bark to create audiobooks.', 'And I bet it would be great for podcasts too.']\n",
      " > Processing time: 5.055911302566528\n",
      " > Real-time factor: 0.3251821423367479\n",
      " > Text splitted to sentences.\n",
      "['I can imagine.', 'It would be like having your own personal voiceover artist.']\n",
      " > Processing time: 3.0160422325134277\n",
      " > Real-time factor: 0.3110674451191863\n",
      " > Text splitted to sentences.\n",
      "['Exactly!', 'I think Bark is going to be a game-changer in the world of text-to-audio technology.']\n",
      " > Processing time: 2.5633115768432617\n",
      " > Real-time factor: 0.33194547705667354\n",
      "Final audio saved as output.wav\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "# Initialize TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
    "\n",
    "# Speaker voice mapping\n",
    "speaker_lookup = {\"Samantha\": \"Voice_2.wav\", \"John\": \"Voice_3.wav\"}\n",
    "\n",
    "# Script generated by ChatGPT\n",
    "script = \"\"\"\n",
    "Samantha: Hey, have you heard about this new text-to-audio model called \"Bark\"?\n",
    "John: No, I haven't. What's so special about it?\n",
    "Samantha: Well, apparently it's the most realistic and natural-sounding text-to-audio model out there right now. People are saying it sounds just like a real person speaking.\n",
    "John: Wow, that sounds amazing. How does it work?\n",
    "Samantha: I think it uses advanced machine learning algorithms to analyze and understand the nuances of human speech, and then replicates those nuances in its own speech output.\n",
    "John: That's pretty impressive. Do you think it could be used for things like audiobooks or podcasts?\n",
    "Samantha: Definitely! In fact, I heard that some publishers are already starting to use Bark to create audiobooks. And I bet it would be great for podcasts too.\n",
    "John: I can imagine. It would be like having your own personal voiceover artist.\n",
    "Samantha: Exactly! I think Bark is going to be a game-changer in the world of text-to-audio technology.\n",
    "\"\"\"\n",
    "\n",
    "# Process script into (speaker, text) pairs\n",
    "lines = [line.strip() for line in script.strip().split(\"\\n\") if line]\n",
    "dialogues = [(line.split(\":\")[0], line.split(\":\")[1].strip()) for line in lines]\n",
    "\n",
    "# Temporary files storage\n",
    "temp_files = []\n",
    "\n",
    "# Generate audio files\n",
    "for i, (speaker, sentence) in enumerate(dialogues):\n",
    "    if speaker not in speaker_lookup:\n",
    "        continue  # Skip unknown speakers\n",
    "\n",
    "    speaker_wav = [speaker_lookup[speaker]]\n",
    "    temp_path = f\"temp_{i}.wav\"\n",
    "\n",
    "    # Generate speech for the current line\n",
    "    tts.tts_to_file(\n",
    "        text=sentence, file_path=temp_path, speaker_wav=speaker_wav, language=\"en\"\n",
    "    )\n",
    "    temp_files.append(temp_path)\n",
    "\n",
    "# Load and concatenate all speech files\n",
    "final_audio = AudioSegment.empty()\n",
    "for file in temp_files:\n",
    "    audio = AudioSegment.from_wav(file)\n",
    "    final_audio += audio + AudioSegment.silent(\n",
    "        duration=500\n",
    "    )  # Adding a slight pause between speakers\n",
    "\n",
    "# Export the concatenated audio\n",
    "final_audio.export(\"output.wav\", format=\"wav\")\n",
    "\n",
    "# Cleanup temporary files\n",
    "for file in temp_files:\n",
    "    os.remove(file)\n",
    "\n",
    "print(\"Final audio saved as output.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
